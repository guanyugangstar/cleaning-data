---
type:
category:
tags:
date: 2026-01-03
---

# CLAUDE.md

  

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

  

## Dependencies

  

```bash

pip install pandas numpy scipy scikit-learn pyyaml openpyxl

```

  

## Project Overview

  

This is a **Claude Code Skill for Data Cleaning** - a specialized tool for cleaning raw datasets containing missing values, duplicates, outliers, inconsistent formats, and other data quality issues. The skill generates and executes Python scripts rather than loading large datasets into LLM context.

  

## Commands

  

```bash

# Run with custom config (user uploads file first, then runs)

python scripts/cleaning_data.py -c configs/custom.yaml -i 数据文件名.csv

  

# Run with default config (auto-generates config)

python scripts/cleaning_data.py -i data/raw_data.csv

  

# Show help

python scripts/cleaning_data.py --help

```

  

## Architecture

  

**Main entry point:** `scripts/cleaning_data.py`

  

### Core Components

  

- **DataCleaner** - 9-phase cleaning pipeline (main class)

- **FileLoader** - Multi-format file loading (CSV/Excel/JSON/Parquet)

- **ConfigGenerator** - Config merging and auto-detection

- **DataLineage** - Track cleaning operations per column

  

### DataCleaner Pipeline (clean method)

  

1. `load_data()` - Load via FileLoader

2. `inspect_data()` - Generate EDA report to `data/EDA-data_{timestamp}.json`

3. `handle_missing_values()` - Fill or drop based on config

4. `handle_duplicates()` - Remove duplicates

5. `handle_outliers()` - IQR/Z-score/MAD/range detection

6. `standardize_format()` - Dates, text trim, case conversion

7. `transform_data()` - Categorical encoding, binning, computed columns

8. `save_results()` - Save cleaned data

9. `get_final_stats()` - Return statistics

  

### ConfigGenerator Auto-Detection

  

When loading `custom.yaml`, the script auto-fills:

- `date_columns` - Column name keywords + content pattern detection

- `trim_columns` - All categorical columns

- `categorical_encoding` - Low-cardinality columns using LabelEncoder

- High missing rate (>50%) columns → marked for deletion

  

**LLM only needs to configure:**

- `outliers.ranges` - Value ranges requiring business semantics

- `transformations.binning` - Binning rules

- `transformations.computed_columns` - Derived columns

  

## Critical Constraints

  

1. **Never pass large datasets to LLM** - Token overflow will occur

2. **Only load first 5 rows for LLM analysis** - Let LLM understand data semantics

3. **Use UTF-8-SIG encoding** - Required for Chinese CSV files

4. **Always backup raw data** - Before any cleaning operations

5. **Config files must use UTF-8 encoding** - Ensure Chinese column names parse correctly

  

## Data Flow

  

| Stage | Location |

|-------|----------|

| Raw data | User-specified via `-i` |

| Custom config | `configs/custom.yaml` (generated by LLM from first 5 rows) |

| EDA report | `data/EDA-data_{timestamp}.json` |

| Lineage report | `data/lineage_report_{timestamp}.yaml` |

| Cleaned data | `data/cleaned_data_{timestamp}.csv` |

  

## Configuration Keys

  

```yaml

data:

  input_path, output_path, encoding: "utf-8-sig"

missing_values:

  strategy (drop/mean/median/mode/fixed), fixed_value, columns

duplicates:

  action (drop/keep_first/keep_last), subset

outliers:

  method (none/iqr/zscore/mad/range), ranges, treatment

format_standardization:

  date_columns, trim_columns, lowercase_columns, title_columns, drop_columns

transformations:

  categorical_encoding, binning, computed_columns

```

  

## Prompt Templates

  

LLM prompt templates stored in `reference/` directory:

- `reference/prompt_generate_config.md` - Generate config prompt

- `reference/prompt_eda_analysis.md` - EDA analysis prompt

  

## SKILL.md Workflow

  

When invoked as a skill:

1. User uploads data file → saved to working directory

2. Load first 5 rows → convert to LLM-readable format

3. LLM analyzes → generates `custom.yaml` with business rules

4. Run `cleaning_data.py -c configs/custom.yaml -i 数据文件名.csv`

  

See `SKILL.md` and `reference/` folder for prompt templates and examples.